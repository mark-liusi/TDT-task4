#!/usr/bin/env python3
"""
åŸŸå·®è·åˆ†æï¼šå¯¹æ¯”åŸå§‹æ¨¡å‹åœ¨MNIST vs è‡ªå®šä¹‰æ•°æ®ä¸Šçš„è¡¨ç°
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np


# æ¨¡å‹å®šä¹‰
class ImprovedNet(nn.Module):
    def __init__(self):
        super(ImprovedNet, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 512)
        self.bn1 = nn.BatchNorm1d(512)
        self.fc2 = nn.Linear(512, 256)
        self.bn2 = nn.BatchNorm1d(256)
        self.fc3 = nn.Linear(256, 128)
        self.bn3 = nn.BatchNorm1d(128)
        self.fc4 = nn.Linear(128, 10)
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        x = x.view(-1, 28 * 28)
        x = F.relu(self.bn1(self.fc1(x)))
        x = self.dropout(x)
        x = F.relu(self.bn2(self.fc2(x)))
        x = self.dropout(x)
        x = F.relu(self.bn3(self.fc3(x)))
        x = self.dropout(x)
        x = self.fc4(x)
        return x


def test_model_on_dataset(model, dataloader, dataset_name, device, remap_labels=False):
    """æµ‹è¯•æ¨¡å‹åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šçš„è¡¨ç°"""
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for data, target in dataloader:
            data, target = data.to(device), target.to(device)

            # å¦‚æœæ˜¯è‡ªå®šä¹‰æ•°æ®é›†ï¼Œéœ€è¦é‡æ–°æ˜ å°„æ ‡ç­¾
            if remap_labels:
                target = target + 1  # ImageFolderçš„0-4æ˜ å°„åˆ°æ¨¡å‹çš„1-5

            output = model(data)
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)

    accuracy = 100.0 * correct / total
    print(f"{dataset_name} å‡†ç¡®ç‡: {accuracy:.2f}% ({correct}/{total})")
    return accuracy


def main():
    print("=" * 60)
    print("ğŸ”¬ åŸŸå·®è·åˆ†æï¼šåŸå§‹æ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„è¡¨ç°")
    print("=" * 60)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # åŠ è½½åŸå§‹æ¨¡å‹
    print("ğŸ“¥ åŠ è½½åŸå§‹MNISTæ¨¡å‹...")
    model = ImprovedNet()
    model.load_state_dict(torch.load("mnist_fc_improved.pth", map_location=device))
    model.to(device)
    print("âœ… åŸå§‹æ¨¡å‹åŠ è½½æˆåŠŸ")

    # 1. æµ‹è¯•åŸå§‹MNISTæ•°æ®é›†ä¸Šçš„è¡¨ç°
    print("\nğŸ§ª æµ‹è¯•1: åŸå§‹æ¨¡å‹åœ¨MNISTæµ‹è¯•é›†ä¸Šçš„è¡¨ç°")
    mnist_transform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,)),  # MNISTä¸“ç”¨æ ‡å‡†åŒ–
        ]
    )

    mnist_test = datasets.MNIST(
        root="./mnist_data", train=False, download=False, transform=mnist_transform
    )
    mnist_loader = DataLoader(mnist_test, batch_size=64, shuffle=False)

    mnist_acc = test_model_on_dataset(
        model, mnist_loader, "MNIST", device, remap_labels=False
    )

    # 2. æµ‹è¯•è‡ªå®šä¹‰æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼ˆä½¿ç”¨MNISTæ ‡å‡†åŒ–ï¼‰
    print("\nğŸ§ª æµ‹è¯•2: åŸå§‹æ¨¡å‹åœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šçš„è¡¨ç°ï¼ˆMNISTæ ‡å‡†åŒ–ï¼‰")
    custom_transform_mnist = transforms.Compose(
        [
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize((28, 28)),
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,)),  # é”™è¯¯ï¼šç”¨MNISTæ ‡å‡†åŒ–
        ]
    )

    custom_dataset_mnist = datasets.ImageFolder(
        root="./number", transform=custom_transform_mnist
    )
    custom_loader_mnist = DataLoader(custom_dataset_mnist, batch_size=64, shuffle=False)

    custom_acc_mnist = test_model_on_dataset(
        model, custom_loader_mnist, "è‡ªå®šä¹‰æ•°æ®(MNISTæ ‡å‡†åŒ–)", device, remap_labels=True
    )

    # 3. æµ‹è¯•è‡ªå®šä¹‰æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼ˆä½¿ç”¨é€šç”¨æ ‡å‡†åŒ–ï¼‰
    print("\nğŸ§ª æµ‹è¯•3: åŸå§‹æ¨¡å‹åœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šçš„è¡¨ç°ï¼ˆé€šç”¨æ ‡å‡†åŒ–ï¼‰")
    custom_transform_general = transforms.Compose(
        [
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize((28, 28)),
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,)),  # æ”¹è¿›ï¼šé€šç”¨æ ‡å‡†åŒ–
        ]
    )

    custom_dataset_general = datasets.ImageFolder(
        root="./number", transform=custom_transform_general
    )
    custom_loader_general = DataLoader(
        custom_dataset_general, batch_size=64, shuffle=False
    )

    custom_acc_general = test_model_on_dataset(
        model,
        custom_loader_general,
        "è‡ªå®šä¹‰æ•°æ®(é€šç”¨æ ‡å‡†åŒ–)",
        device,
        remap_labels=True,
    )

    # 4. å¯¹æ¯”å¾®è°ƒæ¨¡å‹çš„è¡¨ç°
    print("\nğŸ§ª æµ‹è¯•4: å¾®è°ƒæ¨¡å‹åœ¨è‡ªå®šä¹‰æ•°æ®ä¸Šçš„è¡¨ç°")
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    finetuned_model = ImprovedNet()
    finetuned_model.load_state_dict(
        torch.load("mnist_finetuned_on_custom.pth", map_location=device)
    )
    finetuned_model.to(device)

    finetuned_acc = test_model_on_dataset(
        finetuned_model,
        custom_loader_general,
        "å¾®è°ƒæ¨¡å‹(è‡ªå®šä¹‰æ•°æ®)",
        device,
        remap_labels=True,
    )

    # ç»“æœæ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š ç»“æœæ€»ç»“")
    print("=" * 60)
    print(f"1. åŸå§‹æ¨¡å‹ + MNISTæ•°æ®é›†:        {mnist_acc:.2f}%")
    print(f"2. åŸå§‹æ¨¡å‹ + è‡ªå®šä¹‰æ•°æ®(MNISTæ ‡å‡†åŒ–): {custom_acc_mnist:.2f}%")
    print(f"3. åŸå§‹æ¨¡å‹ + è‡ªå®šä¹‰æ•°æ®(é€šç”¨æ ‡å‡†åŒ–): {custom_acc_general:.2f}%")
    print(f"4. å¾®è°ƒæ¨¡å‹ + è‡ªå®šä¹‰æ•°æ®:        {finetuned_acc:.2f}%")

    print(f"\nğŸ” å…³é”®å‘ç°:")
    print(f"   ğŸ“‰ åŸŸå·®è·æŸå¤±: {mnist_acc - custom_acc_general:.2f}% (åŸå§‹â†’è‡ªå®šä¹‰)")
    print(f"   ğŸ“ˆ å¾®è°ƒæå‡: {finetuned_acc - custom_acc_general:.2f}% (åŸå§‹â†’å¾®è°ƒ)")
    print(
        f"   ğŸ¯ æ ‡å‡†åŒ–å½±å“: {custom_acc_general - custom_acc_mnist:.2f}% (MNISTæ ‡å‡†åŒ–â†’é€šç”¨æ ‡å‡†åŒ–)"
    )

    # å¯è§†åŒ–å¯¹æ¯”
    categories = [
        "MNIST\n(åŸå§‹)",
        "è‡ªå®šä¹‰\n(MNISTæ ‡å‡†åŒ–)",
        "è‡ªå®šä¹‰\n(é€šç”¨æ ‡å‡†åŒ–)",
        "è‡ªå®šä¹‰\n(å¾®è°ƒæ¨¡å‹)",
    ]
    accuracies = [mnist_acc, custom_acc_mnist, custom_acc_general, finetuned_acc]

    plt.figure(figsize=(10, 6))
    bars = plt.bar(categories, accuracies, color=["blue", "orange", "green", "red"])
    plt.ylabel("å‡†ç¡®ç‡ (%)")
    plt.title("æ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„è¡¨ç°å¯¹æ¯”")
    plt.ylim(0, 100)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, acc in zip(bars, accuracies):
        plt.text(
            bar.get_x() + bar.get_width() / 2,
            bar.get_height() + 1,
            f"{acc:.1f}%",
            ha="center",
            va="bottom",
        )

    plt.tight_layout()
    plt.savefig("domain_gap_analysis.png", dpi=150, bbox_inches="tight")
    plt.show()

    print(f"\nğŸ’¾ åˆ†æå›¾è¡¨å·²ä¿å­˜ä¸º 'domain_gap_analysis.png'")


if __name__ == "__main__":
    main()
