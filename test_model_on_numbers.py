#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒç”¨è®­ç»ƒæ¨¡å‹æµ‹è¯•numberæ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡
ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ•°å­—è¯†åˆ«
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import os
from PIL import Image
import random


# å®šä¹‰æ”¹è¿›çš„ç½‘ç»œæ¶æ„ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
class ImprovedNet(nn.Module):
    def __init__(self):
        super(ImprovedNet, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 512)
        self.bn1 = nn.BatchNorm1d(512)
        self.fc2 = nn.Linear(512, 256)
        self.bn2 = nn.BatchNorm1d(256)
        self.fc3 = nn.Linear(256, 128)
        self.bn3 = nn.BatchNorm1d(128)
        self.fc4 = nn.Linear(128, 10)
        self.dropout = nn.Dropout(0.3)

    def forward(self, x):
        x = x.view(-1, 28 * 28)
        x = F.relu(self.bn1(self.fc1(x)))
        x = self.dropout(x)
        x = F.relu(self.bn2(self.fc2(x)))
        x = self.dropout(x)
        x = F.relu(self.bn3(self.fc3(x)))
        x = self.dropout(x)
        x = self.fc4(x)
        return x


def load_model(model_path):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = ImprovedNet()

    # åŠ è½½æ¨¡å‹æƒé‡
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.to(device)
        model.eval()
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼ä½¿ç”¨è®¾å¤‡: {device}")
        return model, device
    else:
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None, None


def get_data_loader(data_path, batch_size=32):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    # æ•°æ®é¢„å¤„ç†ï¼ˆä¸å¾®è°ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    transform = transforms.Compose(
        [
            transforms.Grayscale(num_output_channels=1),  # è½¬æ¢ä¸ºç°åº¦å›¾
            transforms.Resize((28, 28)),  # è°ƒæ•´å¤§å°åˆ°28x28
            transforms.ToTensor(),  # è½¬æ¢ä¸ºå¼ é‡
            transforms.Normalize((0.5,), (0.5,)),  # å½’ä¸€åŒ–åˆ°[-1, 1]
        ]
    )

    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
        return None

    try:
        # ä½¿ç”¨ImageFolderåŠ è½½æ•°æ®
        dataset = datasets.ImageFolder(root=data_path, transform=transform)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

        print(f"ğŸ“ æ•°æ®é›†ä¿¡æ¯:")
        print(f"   è·¯å¾„: {data_path}")
        print(f"   ç±»åˆ«: {dataset.classes}")
        print(f"   æ ·æœ¬æ€»æ•°: {len(dataset)}")
        print(f"   ç±»åˆ«æ˜ å°„: {dataset.class_to_idx}")

        return dataloader, dataset
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None, None


def test_model(model, dataloader, device, dataset):
    """æµ‹è¯•æ¨¡å‹å¹¶è¾“å‡ºè¯¦ç»†ç»“æœ"""
    print("\nğŸ§ª å¼€å§‹æµ‹è¯•æ¨¡å‹...")

    model.eval()
    correct = 0
    total = 0
    class_correct = {}
    class_total = {}
    predictions = []
    true_labels = []
    confidences = []

    # åˆå§‹åŒ–ç±»åˆ«ç»Ÿè®¡
    for i, class_name in enumerate(dataset.classes):
        class_correct[i] = 0
        class_total[i] = 0

    # ç±»åˆ«æ˜ å°„ï¼šImageFolderçš„0-4æ˜ å°„åˆ°æ¨¡å‹çš„1-5
    def map_target_to_model(target):
        # ImageFolder: 0,1,2,3,4 å¯¹åº”æ–‡ä»¶å¤¹ 1,2,3,4,5
        # æ¨¡å‹è¾“å‡º: 0-9ï¼Œå…¶ä¸­1,2,3,4,5å¯¹åº”æ•°å­—1,2,3,4,5
        return target + 1

    def map_model_to_target(model_pred):
        # æ¨¡å‹è¾“å‡º1,2,3,4,5æ˜ å°„å›ImageFolderçš„0,1,2,3,4
        if 1 <= model_pred <= 5:
            return model_pred - 1
        else:
            return -1  # æ— æ•ˆé¢„æµ‹

    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(dataloader):
            data, target = data.to(device), target.to(device)

            # å‰å‘ä¼ æ’­
            output = model(data)
            probabilities = F.softmax(output, dim=1)

            # è·å–é¢„æµ‹ç»“æœ
            _, predicted = torch.max(output, 1)

            # ç»Ÿè®¡å„ç±»åˆ«å‡†ç¡®ç‡
            for i in range(target.size(0)):
                true_label = target[i].item()  # ImageFolderçš„æ ‡ç­¾ (0-4)
                model_pred = predicted[i].item()  # æ¨¡å‹é¢„æµ‹ (0-9)
                mapped_pred = map_model_to_target(model_pred)  # æ˜ å°„å› (0-4)

                # è·å–ç½®ä¿¡åº¦
                confidence = probabilities[i][model_pred].item()

                class_total[true_label] += 1
                total += 1

                if mapped_pred == true_label:
                    class_correct[true_label] += 1
                    correct += 1

                # ä¿å­˜è¯¦ç»†ä¿¡æ¯
                predictions.append(mapped_pred)
                true_labels.append(true_label)
                confidences.append(confidence)

            # æ˜¾ç¤ºè¿›åº¦
            if (batch_idx + 1) % 10 == 0:
                print(
                    f"   å·²å¤„ç† {(batch_idx + 1) * dataloader.batch_size} / {len(dataset)} æ ·æœ¬"
                )

    # è¾“å‡ºç»“æœ
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"   æ€»æ ·æœ¬æ•°: {total}")
    print(f"   æ€»ä½“å‡†ç¡®ç‡: {100 * correct / total:.2f}% ({correct}/{total})")
    print(f"   å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.3f}")

    print(f"\nğŸ” å„ç±»åˆ«è¯¦ç»†ç»“æœ:")
    for i, class_name in enumerate(dataset.classes):
        if class_total[i] > 0:
            accuracy = 100 * class_correct[i] / class_total[i]
            print(
                f"   æ•°å­— {class_name}: {accuracy:.2f}% ({class_correct[i]}/{class_total[i]})"
            )
        else:
            print(f"   æ•°å­— {class_name}: æ— æµ‹è¯•æ ·æœ¬")

    return predictions, true_labels, confidences


def visualize_sample_predictions(model, dataset, device, num_samples=12):
    """å¯è§†åŒ–ä¸€äº›æ ·æœ¬çš„é¢„æµ‹ç»“æœ"""
    print(f"\nğŸ–¼ï¸  éšæœºå±•ç¤º {num_samples} ä¸ªé¢„æµ‹æ ·æœ¬...")

    # éšæœºé€‰æ‹©æ ·æœ¬
    indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))

    fig, axes = plt.subplots(3, 4, figsize=(12, 9))
    axes = axes.ravel()

    # ç±»åˆ«æ˜ å°„å‡½æ•°
    def map_model_to_target(model_pred):
        if 1 <= model_pred <= 5:
            return model_pred - 1
        else:
            return -1

    model.eval()
    with torch.no_grad():
        for i, idx in enumerate(indices):
            if i >= 12:  # æœ€å¤šæ˜¾ç¤º12ä¸ª
                break

            # è·å–æ ·æœ¬
            image, true_label = dataset[idx]
            image_batch = image.unsqueeze(0).to(device)

            # é¢„æµ‹
            output = model(image_batch)
            probabilities = F.softmax(output, dim=1)
            confidence, model_predicted = torch.max(probabilities, 1)

            # æ˜ å°„é¢„æµ‹ç»“æœ
            mapped_pred = map_model_to_target(model_predicted.item())

            # æ˜¾ç¤ºå›¾åƒ
            img_np = image.squeeze().cpu().numpy()
            axes[i].imshow(img_np, cmap="gray")

            if mapped_pred >= 0 and mapped_pred < len(dataset.classes):
                pred_class = dataset.classes[mapped_pred]
            else:
                pred_class = f"æ— æ•ˆ({model_predicted.item()})"

            axes[i].set_title(
                f"çœŸå®: {dataset.classes[true_label]}\n"
                f"é¢„æµ‹: {pred_class}\n"
                f"ç½®ä¿¡åº¦: {confidence.item():.3f}",
                fontsize=10,
            )
            axes[i].axis("off")

            # å¦‚æœé¢„æµ‹é”™è¯¯ï¼Œç”¨çº¢è‰²æ ‡é¢˜
            if mapped_pred != true_label:
                axes[i].set_title(
                    f"çœŸå®: {dataset.classes[true_label]}\n"
                    f"é¢„æµ‹: {pred_class}\n"
                    f"ç½®ä¿¡åº¦: {confidence.item():.3f}",
                    fontsize=10,
                    color="red",
                )

    plt.tight_layout()
    plt.savefig("sample_predictions.png", dpi=150, bbox_inches="tight")
    plt.show()
    print("ğŸ’¾ æ ·æœ¬é¢„æµ‹å›¾å·²ä¿å­˜ä¸º sample_predictions.png")


def test_single_image(model, device, image_path, dataset_classes):
    """æµ‹è¯•å•å¼ å›¾ç‰‡"""
    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
        return

    # æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose(
        [
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize((28, 28)),
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,)),
        ]
    )

    def map_model_to_target(model_pred):
        if 1 <= model_pred <= 5:
            return model_pred - 1
        else:
            return -1

    try:
        # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
        image = Image.open(image_path)
        image_tensor = transform(image).unsqueeze(0).to(device)

        # é¢„æµ‹
        model.eval()
        with torch.no_grad():
            output = model(image_tensor)
            probabilities = F.softmax(output, dim=1)
            confidence, model_predicted = torch.max(probabilities, 1)

        mapped_pred = map_model_to_target(model_predicted.item())

        print(f"ğŸ“¸ å•å¼ å›¾ç‰‡æµ‹è¯•: {image_path}")
        if mapped_pred >= 0 and mapped_pred < len(dataset_classes):
            print(f"   é¢„æµ‹ç»“æœ: æ•°å­— {dataset_classes[mapped_pred]}")
        else:
            print(f"   é¢„æµ‹ç»“æœ: æ— æ•ˆé¢„æµ‹ (æ¨¡å‹è¾“å‡º: {model_predicted.item()})")
        print(f"   ç½®ä¿¡åº¦: {confidence.item():.3f}")

        # æ˜¾ç¤ºæ‰€æœ‰æ•°å­—ç±»åˆ«çš„æ¦‚ç‡
        print("   å„æ•°å­—ç±»åˆ«æ¦‚ç‡:")
        for digit in [1, 2, 3, 4, 5]:  # åªæ˜¾ç¤ºæˆ‘ä»¬å…³å¿ƒçš„æ•°å­—
            prob = probabilities[0][digit].item()
            print(f"     æ•°å­— {digit}: {prob:.3f}")

    except Exception as e:
        print(f"âŒ å•å¼ å›¾ç‰‡æµ‹è¯•å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ æ•°å­—è¯†åˆ«æ¨¡å‹æµ‹è¯•ç¨‹åº")
    print("=" * 60)

    # é…ç½®å‚æ•°
    model_path = "mnist_finetuned_on_custom.pth"  # å¾®è°ƒåçš„æ¨¡å‹
    data_path = "./number"  # æµ‹è¯•æ•°æ®è·¯å¾„
    batch_size = 32

    # æ£€æŸ¥æ˜¯å¦æœ‰å¾®è°ƒæ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰å°±ä½¿ç”¨åŸå§‹æ¨¡å‹
    if not os.path.exists(model_path):
        print(f"âš ï¸  å¾®è°ƒæ¨¡å‹ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ¨¡å‹...")
        model_path = "mnist_fc_improved.pth"

    # åŠ è½½æ¨¡å‹
    model, device = load_model(model_path)
    if model is None:
        return

    # åŠ è½½æµ‹è¯•æ•°æ®
    result = get_data_loader(data_path, batch_size)
    if result is None:
        return
    dataloader, dataset = result

    # æµ‹è¯•æ¨¡å‹
    predictions, true_labels, confidences = test_model(
        model, dataloader, device, dataset
    )

    # å¯è§†åŒ–æ ·æœ¬é¢„æµ‹
    visualize_sample_predictions(model, dataset, device)

    # æµ‹è¯•å•å¼ å›¾ç‰‡ç¤ºä¾‹ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
    print(f"\nğŸ” å¯»æ‰¾å•å¼ å›¾ç‰‡è¿›è¡Œæµ‹è¯•...")
    for class_name in dataset.classes:
        class_dir = os.path.join(data_path, class_name)
        if os.path.exists(class_dir):
            images = [
                f
                for f in os.listdir(class_dir)
                if f.lower().endswith((".png", ".jpg", ".jpeg"))
            ]
            if images:
                sample_image = os.path.join(class_dir, images[0])
                test_single_image(model, device, sample_image, dataset.classes)
                break

    print(f"\nâœ… æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()
